{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1tcfFkpKh5xufTFK7POC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ugur-sa/Bachelorarbeit/blob/main/SentimentTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hole HTML-Dokument der Nachricht über dessen Link und bereinige es grob"
      ],
      "metadata": {
        "id": "i9O0E1v-r_eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "res = requests.get(\"https://finance.yahoo.com/news/us-stocks-p-500-wobbles-210042198.html\")\n",
        "\n",
        "soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "for meta in soup.find_all(\"meta\"):\n",
        "    meta.decompose()\n",
        "\n",
        "for script in soup.find_all(\"script\"):\n",
        "    script.decompose()\n",
        "\n",
        "for noscript in soup.find_all(\"noscript\"):\n",
        "    noscript.decompose()\n",
        "\n",
        "for link in soup.find_all(\"link\"):\n",
        "    link.decompose()\n",
        "\n",
        "for style in soup.find_all(\"style\"):\n",
        "    style.decompose()\n",
        "\n",
        "for html in soup.find_all('html'):\n",
        "    html.unwrap()\n",
        "\n",
        "# title = soup.find(\"title\").text\n",
        "\n",
        "soup = soup.find(\"div\", attrs={'class':'caas-body'})"
      ],
      "metadata": {
        "id": "LhSPYOfPnEcg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hier wird weiter gearbeitet mit dem Div-Element, dass den Nachrichtentext enthält. Hierbei wird der pure Text extrahiert und Listen, Buttons und die Tags selber entfernt."
      ],
      "metadata": {
        "id": "nibLTftusES1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for div in soup.find_all('div'):\n",
        "    div.unwrap()\n",
        "\n",
        "for ul in soup.find_all('ul'):\n",
        "    # Finde das unmittelbar vorhergehende <p>-Tag, wenn vorhanden\n",
        "    p_tag = ul.find_previous_sibling('p')\n",
        "\n",
        "    # Wenn ein <p>-Tag gefunden wurde, entferne es\n",
        "    if p_tag:\n",
        "        p_tag.decompose()\n",
        "\n",
        "# Entferne alle <div>-Elemente\n",
        "for ul in soup.find_all(\"ul\"):\n",
        "    ul.decompose()\n",
        "\n",
        "for button in soup.find_all(\"button\"):\n",
        "    button.decompose()\n",
        "\n",
        "for p_tag in soup.find_all('p', string=\"©2023 Bloomberg L.P.\"):\n",
        "    p_tag.decompose()\n",
        "\n",
        "# text_lines = [p.get_text() + '\\n' for p in soup.find_all('p')]\n",
        "\n",
        "for p in soup.find_all('p'):\n",
        "  print(p.text)\n",
        "\n",
        "# print(text_lines)"
      ],
      "metadata": {
        "id": "EAdeeodMp5XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klassifiziere die Nachricht mit einem vortrainierten Modell mit der Huggingsface Bibliothek und PyTorch"
      ],
      "metadata": {
        "id": "_Qi8Hmbgq8Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"nickmuchi/distilroberta-finetuned-financial-text-classification\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Dein Text\n",
        "text = \"\"\n",
        "\n",
        "for p in soup.find_all('p'):\n",
        "  text = text + p.text + \"\\n\"\n",
        "# Tokenisiere den Text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Wende das Modell an\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Hole die Modellvorhersagen\n",
        "predictions = outputs.logits\n",
        "\n",
        "# Konvertiere Vorhersagen in Wahrscheinlichkeiten und hole das maximale\n",
        "predictions = torch.nn.functional.softmax(predictions, dim=1)\n",
        "predicted_class = torch.argmax(predictions).item()\n",
        "\n",
        "# Zuordnung der Klassen\n",
        "classes = [\"bearish\", \"neutral\", \"bullish\"]\n",
        "\n",
        "# Ergebnis\n",
        "print(f\"Sentiment: {classes[predicted_class]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd0hdSkCq7nr",
        "outputId": "595217e2-7933-4ed0-bd38-a74021c45b2d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: bullish\n"
          ]
        }
      ]
    }
  ]
}