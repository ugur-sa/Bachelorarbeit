{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ugur-sa/Bachelorarbeit/blob/main/SentimentTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://finance.yahoo.com/news/nuclear-backers-pressure-biden-industry-203353816.html\n"
          ]
        }
      ],
      "source": [
        "# lies die Zeilen der datei links.txt aus und gib die länge der liste aus\n",
        "\n",
        "with open(\"links.txt\", 'r') as f:\n",
        "    links = [line.strip() for line in f.readlines()] #strip() entfernt \\n \n",
        "\n",
        "print(links[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhSPYOfPnEcg",
        "outputId": "d4ab3dc6-adff-4ce7-bf6f-2c037461abe7"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "import time\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "model_name = \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "for link in links:\n",
        "    link = link.strip()\n",
        "    res = requests.get(link)\n",
        "\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "    title = soup.find(\"title\").text\n",
        "    print(title)\n",
        "\n",
        "    soup = soup.find(\"div\", attrs={'class':'caas-body'})\n",
        "\n",
        "    if(soup == None or title == 'Yahoo'):\n",
        "        continue\n",
        "\n",
        "    for div in soup.find_all('div'):\n",
        "        div.unwrap()\n",
        "\n",
        "    for ul in soup.find_all('ul'):\n",
        "        # Finde das unmittelbar vorhergehende <p>-Tag, wenn vorhanden\n",
        "        p_tag = ul.find_previous_sibling('p')\n",
        "\n",
        "        # Wenn ein <p>-Tag gefunden wurde, entferne es\n",
        "        if p_tag:\n",
        "            p_tag.decompose()\n",
        "\n",
        "    # Entferne alle <div>-Elemente\n",
        "    for ul in soup.find_all(\"ul\"):\n",
        "        ul.decompose()\n",
        "\n",
        "    for button in soup.find_all(\"button\"):\n",
        "        button.decompose()\n",
        "\n",
        "    for p_tag in soup.find_all('p', string=\"©2023 Bloomberg L.P.\"):\n",
        "        p_tag.decompose()\n",
        "\n",
        "    # Dein Text\n",
        "    text = \"\"\n",
        "\n",
        "    for p in soup.find_all('p'):\n",
        "        text = text + p.text + \"\\n\"\n",
        "    # Tokenisiere den Text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    # Wende das Modell an\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Hole die Modellvorhersagen\n",
        "    predictions = outputs.logits\n",
        "\n",
        "    # Konvertiere Vorhersagen in Wahrscheinlichkeiten und hole das maximale\n",
        "    predictions = torch.nn.functional.softmax(predictions, dim=1)\n",
        "    predicted_class = torch.argmax(predictions).item()\n",
        "\n",
        "    # Zuordnung der Klassen\n",
        "    classes = [\"bearish\", \"neutral\", \"bullish\"]\n",
        "\n",
        "    # Ergebnis\n",
        "    print(f\"Sentiment: {classes[predicted_class]}\")\n",
        "    # speichere das ergebnis in einer datenbank\n",
        "\n",
        "    conn = sqlite3.connect('sentiment.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Create table with title, link, text, sentiment\n",
        "    c.execute('''CREATE TABLE IF NOT EXISTS sentiment\n",
        "                (title text, link text, text text, sentiment text)''')\n",
        "\n",
        "    # Insert a row of data\n",
        "    c.execute(\"INSERT INTO sentiment VALUES (?, ?, ?, ?)\", (title, link, text, classes[predicted_class]))\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMKzgHyaSfgbYoQiDjlUFSh",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
