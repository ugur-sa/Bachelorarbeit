{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Initialisiere den WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigiere zur Webseite\n",
    "driver.get(\"https://finance.yahoo.com/news\")\n",
    "\n",
    "scroll_button = driver.find_element(By.ID, \"scroll-down-btn\")\n",
    "scroll_button.click()\n",
    "cookie_button = driver.find_element(By.CLASS_NAME, \"reject-all\")\n",
    "cookie_button.click()\n",
    "\n",
    "html_element = driver.find_element(By.TAG_NAME, 'html')\n",
    "\n",
    "# Drücke 10 Mal die \"End\"-Taste, um ans Ende der Seite zu scrollen\n",
    "for _ in range(16):\n",
    "    html_element.send_keys(Keys.END)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Hole das HTML der Seite\n",
    "html = driver.page_source\n",
    "\n",
    "# Schließe den Browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwende BeautifulSoup, um das HTML zu parsen\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "# Finde alle Artikel\n",
    "articles = soup.find_all('li', class_='js-stream-content Pos(r)')\n",
    "\n",
    "# Check if the li has a div with content \"Business\" and only keep those\n",
    "\n",
    "business_articles = []\n",
    "\n",
    "for article in articles:\n",
    "    bsn = article.find_all('div', string='Business')\n",
    "    if bsn:\n",
    "        business_articles.append(article)\n",
    "\n",
    "\n",
    "links = []\n",
    "# extrahiere href von a-Tag\n",
    "for article in business_articles:\n",
    "    link = article.find('a')\n",
    "    # füge finance.yahoo.com vorne an\n",
    "    link = 'https://finance.yahoo.com' + link['href']\n",
    "    links.append(link)\n",
    "\n",
    "# füge die Links in eine Datei ein aber lösche die alten Daten nicht\n",
    "with open('links.txt', 'a') as f:\n",
    "    for link in links:\n",
    "        f.write(link + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
