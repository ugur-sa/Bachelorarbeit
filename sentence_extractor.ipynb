{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPMorgan chief executive Jamie Dimon and other major banks warned lawmakers Wednesday that capital hikes and other new regulations being contemplated by U.S. bank regulators will hurt lending, capital markets and the broader economy.\n",
      "\n",
      "The industry has been waging a fierce campaign to kill the \"Basel endgame\" proposal, which overhauls how banks must calculate their loss-absorbing capital, and as regulators roll out fair lending and fee cap regulations, among other rules.\n",
      "\n",
      "The CEOs hope to use the hearing as an opportunity to try to convince key moderate Democratic senators that the rule, which is being led by the Federal Reserve, could stifle lending, hurting small businesses and consumers.\n",
      "\n",
      "\"If enacted as drafted, this proposal will fundamentally alter the U.S. economy in ways that the Federal Reserve has not studied or contemplated,\" Dimon, CEO of the country's largest lender JPMorgan, said in his prepared testimony published by the Committee on Tuesday.\n",
      "\n",
      "Senator Sherrod Brown, the Ohio Democrat who chairs the Committee, quickly criticized the banks for aggressively lobbying against the rules, including with multiple public advertising campaigns and meetings with lawmakers.\n",
      "\n",
      "Banks have overstated the adverse potential impact of the rules in a bid to preserve their profit margins, he added.\n",
      "\n",
      "\"Absolutely nothing in these rules would stop your banks from making loans to working families,\" he said.\n",
      "\n",
      "\"What your banks want is to maximize quarterly profits, the cost of everything and everyone else be damned.\"\n",
      "\n",
      "The other CEOs appearing are: Bank of America's Brian Moynihan, Wells Fargo's Charles Scharf, Goldman Sachs' David Solomon, Morgan Stanley's James Gorman, State Street's Ronald O'Hanley, and BNY Mellon's Robin Vince.\n",
      "\n",
      "Regulators say new rules, including capital hikes, are necessary to protect the banking system from unforeseen shocks, especially following the collapse of Silicon Valley Bank and two other lenders earlier this year.\n",
      "\n",
      "While CEOs are expected to have the support of Republicans who generally oppose tight regulations, they will have to persuade skeptical Democratic lawmakers that the banking sector is sound.\n",
      "\n",
      "Senator Tim Scott, the panel's top Republican, echoed bank concerns, saying the proposed rules could have a \"devastating impact\" on small businesses.\n",
      "\n",
      "Big bank CEOs have been appearing before Congress for several years after the 2007-09 financial crisis and subsequent scandals thrust the industry into Washington's crosshairs.\n",
      "\n",
      "While they rarely result in legislation, hearings have led banks to make changes.\n",
      "\n",
      "In 2021, Dimon was drawn into a fiery exchange with Democratic Senator Elizabeth Warren about overdraft fees, while last year she grilled him over fraud on bank payment network Zelle.\n",
      "\n",
      "Big banks subsequently reduced overdraft fees and expanded Zelle fraud protections.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "\n",
    "# NLTK's vordefinierte Abk端rzungen laden\n",
    "punkt_param = PunktParameters()\n",
    "\n",
    "# Eigene Abk端rzungen hinzuf端gen\n",
    "abbreviation_types = set(['no', 'dr', 'vs', 'mr', 'mrs', 'prof', 'inc', 'a.m', 'p.m', 'u.s'])\n",
    "punkt_param.abbrev_types.update(abbreviation_types)\n",
    "\n",
    "# Benutzerdefinierten PunktSentenceTokenizer erstellen\n",
    "tokenizer = PunktSentenceTokenizer(punkt_param)\n",
    "\n",
    "def sentence_tokenize(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    n = text.find(') -')\n",
    "    if n != -1:\n",
    "        text = text[n+4:]\n",
    "\n",
    "    # Regex-Muster, das Text in Klammern am Ende des Strings erfasst\n",
    "    pattern = r'\\s*\\([^)]*\\)\\s*$'\n",
    "\n",
    "    # Entferne den Text in Klammern am Ende des Strings\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Entferne alle Zeilenumbr端che\n",
    "    cleaned_text = cleaned_text.replace('\\n', ' ')\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('sentiment.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the sentence table if it doesn't exist\n",
    "# cursor.execute('''\n",
    "#     CREATE TABLE IF NOT EXISTS sentences (\n",
    "#         id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#         text_id INTEGER,\n",
    "#         sentence_text TEXT,\n",
    "#         sequence INTEGER,\n",
    "#         finbert_result TEXT,\n",
    "#         dffnsa_result TEXT,\n",
    "#         fsa_result TEXT,\n",
    "#         final_sentiment TEXT,\n",
    "#         FOREIGN KEY (text_id) REFERENCES sentiment(id)\n",
    "#     )\n",
    "# ''')\n",
    "\n",
    "# Retrieve the texts from the sentiment table\n",
    "cursor.execute('SELECT id, text FROM sentiment WHERE id = 140')\n",
    "texts = cursor.fetchall()\n",
    "\n",
    "# Iterate over each text\n",
    "for text_id, text in texts:\n",
    "    cleaned_text = clean_text(text)\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sentence_tokenize(cleaned_text)\n",
    "    \n",
    "    # Insert each sentence into the sentence table\n",
    "    for sequence, sentence in enumerate(sentences):\n",
    "        # cursor.execute('''\n",
    "        #     INSERT INTO sentences (text_id, sentence_text, sequence)\n",
    "        #     VALUES (?, ?, ?)\n",
    "        # ''', (text_id, sentence, sequence))\n",
    "         print(sentence + '\\n')\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
